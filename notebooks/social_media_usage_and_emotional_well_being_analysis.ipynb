{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFX2BXh6nuBv"
      },
      "source": [
        "# Dataset:  [Social Media Usage and Emotional Well-Being](https://www.kaggle.com/datasets/emirhanai/social-media-usage-and-emotional-well-being)\n",
        "- Tópicos Especiais - Sistemas para Internet - IFPB\n",
        "- Data: 11/03/2025\n",
        "- Análise por Allan Alves Amâncio (no Google Colab)\n",
        "\n",
        "Target: *Dominant_Emotion*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OfenRristVe",
        "outputId": "69b485ea-7512-42f9-c959-7b86d86245a5"
      },
      "outputs": [],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import mode\n",
        "from sklearn import metrics, tree\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import adjusted_rand_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder\n",
        "import time\n",
        "\n",
        "path = \"/root/.cache/kagglehub/datasets/emirhanai/social-media-usage-and-emotional-well-being/versions/1\"\n",
        "file_path = os.path.join(path, \"train.csv\")\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    print(\"Fazendo download do dataset...\")\n",
        "    path = kagglehub.dataset_download(\"emirhanai/social-media-usage-and-emotional-well-being\")\n",
        "else:\n",
        "    print(\"Dataset já baixado. Continuando...\")\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "df.drop(columns=['User_ID', 'Platform'], inplace=True, axis=1)\n",
        "\n",
        "df = df[df[\"Gender\"].isin([\"Male\", \"Female\", \"Non-binary\"])]\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"Dominant_Emotion\"] = label_encoder.fit_transform(df[\"Dominant_Emotion\"])\n",
        "\n",
        "column_transformer_one_hot = make_column_transformer(\n",
        "    (OneHotEncoder(), [\"Gender\"]),\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "numeric_cols = df.columns.difference([\"Dominant_Emotion\", \"Gender\"])\n",
        "scaler = MinMaxScaler()\n",
        "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "\n",
        "df_transformed = column_transformer_one_hot.fit_transform(df)\n",
        "new_column_names = column_transformer_one_hot.get_feature_names_out()\n",
        "df = pd.DataFrame(df_transformed, columns=new_column_names)\n",
        "\n",
        "dominant_emotion_col = [col for col in df.columns if \"remainder__Dominant_Emotion\" in col][0]\n",
        "df[dominant_emotion_col] = df[dominant_emotion_col].astype(int)\n",
        "\n",
        "dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "\n",
        "y = df[dominant_emotion_col]\n",
        "X = df.drop(columns=[dominant_emotion_col])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, stratify=y)\n",
        "\n",
        "print(\"\\nALGORITMOS A EXECUTAR E COMPARAR\")\n",
        "\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"\\n1. Árvores de Decisão (Gini e Entropy):\")\n",
        "\n",
        "tree_model_gini = tree.DecisionTreeClassifier(criterion=\"gini\")\n",
        "tree_model_entropy = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
        "\n",
        "scores_tree_model_gini = cross_val_score(tree_model_gini, X, y, cv=kf, scoring='accuracy')\n",
        "scores_tree_model_entropy = cross_val_score(tree_model_entropy, X, y, cv=kf, scoring='accuracy')\n",
        "\n",
        "mean_accuracy_tree_model_gini = np.mean(scores_tree_model_gini) * 100\n",
        "mean_accuracy_tree_model_entropy = np.mean(scores_tree_model_entropy) * 100\n",
        "\n",
        "print(f\"\\nMédia de acurácia (10 folds) com Gini: {mean_accuracy_tree_model_gini:.2f}%\")\n",
        "print(f\"\\nMédia de acurácia (10 folds) com Entropy: {mean_accuracy_tree_model_entropy:.2f}%\")\n",
        "\n",
        "print(\"\\n2. kNN (k igual a 5 e 10):\")\n",
        "\n",
        "knn_model_five_neighbors = KNeighborsClassifier(n_neighbors=5, metric='euclidean', algorithm='brute')\n",
        "knn_model_ten_neighbors = KNeighborsClassifier(n_neighbors=10, metric='euclidean', algorithm='brute')\n",
        "\n",
        "scores_knn_model_five_neighbors = cross_val_score(knn_model_five_neighbors, X, y, cv=kf, scoring='accuracy')\n",
        "scores_knn_model_ten_neighbors = cross_val_score(knn_model_ten_neighbors, X, y, cv=kf, scoring='accuracy')\n",
        "\n",
        "mean_accuracy_knn_model_five_neighbors = np.mean(scores_knn_model_five_neighbors) * 100\n",
        "mean_accuracy_knn_model_ten_neighbors = np.mean(scores_knn_model_ten_neighbors) * 100\n",
        "\n",
        "print(f\"\\nMédia de acurácia (10 folds) com kNN (k = 5 vizinhos): {mean_accuracy_knn_model_five_neighbors:.2f}%\")\n",
        "print(f\"\\nMédia de acurácia (10 folds) com kNN (k = 10 vizinhos): {mean_accuracy_knn_model_ten_neighbors:.2f}%\")\n",
        "\n",
        "print(\"\\n3. MLP com duas arquiteturas diferentes (e com funções de ativação 'Tanh' e 'ReLU' em cada arquitetura):\")\n",
        "\n",
        "mlp_model_one_tanh = MLPClassifier(hidden_layer_sizes=(64,32,16), activation='tanh', max_iter=1500, early_stopping=True, alpha=0.001, learning_rate_init=0.03)\n",
        "mlp_model_one_relu = MLPClassifier(hidden_layer_sizes=(64,32,16), activation='relu', max_iter=1500, early_stopping=True, alpha=0.001, learning_rate_init=0.03)\n",
        "\n",
        "mlp_model_two_tanh = MLPClassifier(hidden_layer_sizes=(128,64,32), activation='tanh', max_iter=1500, early_stopping=True, alpha=0.001, learning_rate_init=0.015)\n",
        "mlp_model_two_relu = MLPClassifier(hidden_layer_sizes=(128,64,32), activation='relu', max_iter=1500, early_stopping=True, alpha=0.001, learning_rate_init=0.015)\n",
        "\n",
        "start_time = time.time()\n",
        "scores_mlp_model_one_tanh = cross_val_score(mlp_model_one_tanh, X, y, cv=kf, scoring='accuracy')\n",
        "elapsed_time_one_tanh = time.time() - start_time\n",
        "mean_accuracy_mlp_model_one_tanh = np.mean(scores_mlp_model_one_tanh) * 100\n",
        "print(f\"\\nMédia de acurácia (10 folds) com MLP 1 (tanh): {mean_accuracy_mlp_model_one_tanh:.2f}% (Tempo: {elapsed_time_one_tanh:.2f}s)\")\n",
        "\n",
        "start_time = time.time()\n",
        "scores_mlp_model_one_relu = cross_val_score(mlp_model_one_relu, X, y, cv=kf, scoring='accuracy')\n",
        "elapsed_time_one_relu = time.time() - start_time\n",
        "mean_accuracy_mlp_model_one_relu = np.mean(scores_mlp_model_one_relu) * 100\n",
        "print(f\"\\nMédia de acurácia (10 folds) com MLP 1 (relu): {mean_accuracy_mlp_model_one_relu:.2f}% (Tempo: {elapsed_time_one_relu:.2f}s)\")\n",
        "\n",
        "start_time = time.time()\n",
        "scores_mlp_model_two_tanh = cross_val_score(mlp_model_two_tanh, X, y, cv=kf, scoring='accuracy')\n",
        "elapsed_time_two_tanh = time.time() - start_time\n",
        "mean_accuracy_mlp_model_two_tanh = np.mean(scores_mlp_model_two_tanh) * 100\n",
        "print(f\"\\nMédia de acurácia (10 folds) com MLP 2 (tanh): {mean_accuracy_mlp_model_two_tanh:.2f}% (Tempo: {elapsed_time_two_tanh:.2f}s)\")\n",
        "\n",
        "start_time = time.time()\n",
        "scores_mlp_model_two_relu = cross_val_score(mlp_model_two_relu, X, y, cv=kf, scoring='accuracy')\n",
        "elapsed_time_two_relu = time.time() - start_time\n",
        "mean_accuracy_mlp_model_two_relu = np.mean(scores_mlp_model_two_relu) * 100\n",
        "print(f\"\\nMédia de acurácia (10 folds) com MLP 2 (relu): {mean_accuracy_mlp_model_two_relu:.2f}% (Tempo: {elapsed_time_two_relu:.2f}s)\")\n",
        "\n",
        "print(\"\\n4. K-Means (K igual ao número de classes existente no problema):\")\n",
        "\n",
        "num_clusters = len(np.unique(y))\n",
        "print(f\"\\nNúmero de clusters escolhido para K-Means: {num_clusters}\")\n",
        "\n",
        "ari_scores_kmeans_model = []\n",
        "accuracies = []\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    kmeans_model = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
        "    kmeans_model.fit(X_train)\n",
        "\n",
        "    y_pred_kmeans = kmeans_model.predict(X_test)\n",
        "\n",
        "    ari = adjusted_rand_score(y_test, y_pred_kmeans)\n",
        "    ari_scores_kmeans_model.append(ari)\n",
        "\n",
        "    labels = np.zeros_like(y_pred_kmeans)\n",
        "    for i in range(num_clusters):\n",
        "        mask = (y_pred_kmeans == i)\n",
        "        labels[mask] = mode(y_test[mask])[0]\n",
        "\n",
        "    accuracy = np.mean(labels == y_test)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "mean_ari_kmeans = np.mean(ari_scores_kmeans_model)\n",
        "mean_accuracy_kmeans_model = np.mean(accuracies) * 100\n",
        "\n",
        "print(f\"\\nMédia de ARI (10 folds): {mean_ari_kmeans:.4f}\")\n",
        "print(f\"\\nMédia de Acurácia (10 folds): {mean_accuracy_kmeans_model:.2f}%\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_mlp_training_loss(histories, labels):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for history, label in zip(histories, labels):\n",
        "        plt.plot(history.loss_curve_, label=label)\n",
        "    \n",
        "    plt.xlabel(\"Épocas\")\n",
        "    plt.ylabel(\"Erro de Treinamento\")\n",
        "    plt.title(\"Taxa de Erro de Treinamento por Época (MLPs)\")\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "mlp_one_tanh = MLPClassifier(hidden_layer_sizes=(64,32,16), activation='tanh', max_iter=1500, early_stopping=True, alpha=0.001, learning_rate_init=0.03)\n",
        "mlp_one_relu = MLPClassifier(hidden_layer_sizes=(64,32,16), activation='relu', max_iter=1500, early_stopping=True, alpha=0.001, learning_rate_init=0.03)\n",
        "mlp_two_tanh = MLPClassifier(hidden_layer_sizes=(128,64,32), activation='tanh', max_iter=1500, early_stopping=True, alpha=0.001, learning_rate_init=0.015)\n",
        "mlp_two_relu = MLPClassifier(hidden_layer_sizes=(128,64,32), activation='relu', max_iter=1500, early_stopping=True, alpha=0.001, learning_rate_init=0.015)\n",
        "\n",
        "mlp_one_tanh.fit(X_train, y_train)\n",
        "mlp_one_relu.fit(X_train, y_train)\n",
        "mlp_two_tanh.fit(X_train, y_train)\n",
        "mlp_two_relu.fit(X_train, y_train)\n",
        "\n",
        "plot_mlp_training_loss([\n",
        "    mlp_one_tanh, mlp_one_relu, mlp_two_tanh, mlp_two_relu\n",
        "], labels=[\n",
        "    \"MLP 1 (tanh)\", \"MLP 1 (relu)\", \"MLP 2 (tanh)\", \"MLP 2 (relu)\"\n",
        "])\n",
        "\n",
        "print(\"\\nTabela das taxas de acerto e erro dos algoritmos\")\n",
        "\n",
        "data = {\n",
        "    \"Algoritmo\": [\n",
        "        \"Árvore de Decisão (Gini)\", \"Árvore de Decisão (Entropy)\",\n",
        "        \"kNN (k=5)\", \"kNN (k=10)\",\n",
        "        \"MLP 1 (tanh)\", \"MLP 1 (relu)\", \"MLP 2 (tanh)\", \"MLP 2 (relu)\",\n",
        "        \"K-Means\"\n",
        "    ],\n",
        "    \"Acurácia Média (%)\": [\n",
        "        mean_accuracy_tree_model_gini,\n",
        "        mean_accuracy_tree_model_entropy,\n",
        "        mean_accuracy_knn_model_five_neighbors,\n",
        "        mean_accuracy_knn_model_ten_neighbors,\n",
        "        mean_accuracy_mlp_model_one_tanh,\n",
        "        mean_accuracy_mlp_model_one_relu,\n",
        "        mean_accuracy_mlp_model_two_tanh,\n",
        "        mean_accuracy_mlp_model_two_relu,\n",
        "        mean_accuracy_kmeans_model\n",
        "    ],\n",
        "    \"Taxa de Erro (%)\": [\n",
        "        100 - mean_accuracy_tree_model_gini,\n",
        "        100 - mean_accuracy_tree_model_entropy,\n",
        "        100 - mean_accuracy_knn_model_five_neighbors,\n",
        "        100 - mean_accuracy_knn_model_ten_neighbors,\n",
        "        100 - mean_accuracy_mlp_model_one_tanh,\n",
        "        100 - mean_accuracy_mlp_model_one_relu,\n",
        "        100 - mean_accuracy_mlp_model_two_tanh,\n",
        "        100 - mean_accuracy_mlp_model_two_relu,\n",
        "        100 - mean_accuracy_kmeans_model\n",
        "    ]\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(data)\n",
        "print(results_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
