{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFX2BXh6nuBv"
      },
      "source": [
        "# Dataset:  [Social Media Usage and Emotional Well-Being](https://www.kaggle.com/datasets/emirhanai/social-media-usage-and-emotional-well-being)\n",
        "- Tópicos Especiais - Sistemas para Internet - IFPB\n",
        "- Data: 10/03/2025\n",
        "- Análise por Allan Alves Amâncio (feita no Google Colab)\n",
        "\n",
        "Target: *Dominant_Emotion*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OfenRristVe",
        "outputId": "57897a72-9f45-4fc9-9994-443c8a16bcc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset já baixado. Continuando...\n",
            "\n",
            "ALGORITMOS A EXECUTAR E COMPARAR\n",
            "\n",
            "1. Árvores de Decisão (Gini e Entropy):\n",
            "\n",
            "Média de acurácia (10 folds) com Gini: 96.54%\n",
            "\n",
            "Média de acurácia (10 folds) com Entropy: 96.32%\n",
            "\n",
            "2. kNN (k igual a 5 e 10):\n",
            "\n",
            "Média de acurácia (10 folds) com kNN (k = 5 vizinhos): 99.14%\n",
            "\n",
            "Média de acurácia (10 folds) com kNN (k = 10 vizinhos): 95.24%\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics, tree\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
        "import time\n",
        "\n",
        "path = \"/root/.cache/kagglehub/datasets/emirhanai/social-media-usage-and-emotional-well-being/versions/1\"\n",
        "file_path = os.path.join(path, \"train.csv\")\n",
        "\n",
        "if not os.path.exists(file_path):\n",
        "    print(\"Fazendo download do dataset...\")\n",
        "    path = kagglehub.dataset_download(\"emirhanai/social-media-usage-and-emotional-well-being\")\n",
        "else:\n",
        "    print(\"Dataset já baixado. Continuando...\")\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "df.drop(columns=['User_ID', 'Platform'], inplace=True, axis=1)\n",
        "\n",
        "df = df[df[\"Gender\"].isin([\"Male\", \"Female\", \"Non-binary\"])]\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "df[\"Dominant_Emotion\"] = label_encoder.fit_transform(df[\"Dominant_Emotion\"])\n",
        "\n",
        "column_transformer_one_hot = make_column_transformer(\n",
        "    (OneHotEncoder(), [\"Gender\"]),\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "numeric_cols = df.columns.difference([\"Dominant_Emotion\", \"Gender\"])\n",
        "scaler = MinMaxScaler()\n",
        "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
        "\n",
        "df_transformed = column_transformer_one_hot.fit_transform(df)\n",
        "new_column_names = column_transformer_one_hot.get_feature_names_out()\n",
        "df = pd.DataFrame(df_transformed, columns=new_column_names)\n",
        "\n",
        "dominant_emotion_col = [col for col in df.columns if \"remainder__Dominant_Emotion\" in col][0]\n",
        "df[dominant_emotion_col] = df[dominant_emotion_col].astype(int)\n",
        "\n",
        "dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
        "\n",
        "y = df[dominant_emotion_col]\n",
        "X = df.drop(columns=[dominant_emotion_col])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=None, stratify=y)\n",
        "\n",
        "print(\"\\nALGORITMOS A EXECUTAR E COMPARAR\")\n",
        "\n",
        "print(\"\\n1. Árvores de Decisão (Gini e Entropy):\")\n",
        "\n",
        "tree_model_gini = tree.DecisionTreeClassifier(criterion=\"gini\")\n",
        "tree_model_entropy = tree.DecisionTreeClassifier(criterion=\"entropy\")\n",
        "\n",
        "kf_tree_model_gini = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "kf_tree_model_entropy = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "scores_tree_model_gini = cross_val_score(tree_model_gini, X, y, cv=kf_tree_model_gini, scoring='accuracy')\n",
        "scores_tree_model_entropy = cross_val_score(tree_model_entropy, X, y, cv=kf_tree_model_entropy, scoring='accuracy')\n",
        "\n",
        "mean_accuracy_tree_model_gini = np.mean(scores_tree_model_gini) * 100\n",
        "mean_accuracy_tree_model_entropy = np.mean(scores_tree_model_entropy) * 100\n",
        "\n",
        "print(\"\\nMédia de acurácia (10 folds) com Gini: {:.2f}%\".format(mean_accuracy_tree_model_gini))\n",
        "print(\"\\nMédia de acurácia (10 folds) com Entropy: {:.2f}%\".format(mean_accuracy_tree_model_entropy))\n",
        "\n",
        "print(\"\\n2. kNN (k igual a 5 e 10):\")\n",
        "\n",
        "knn_model_five_neighbors = KNeighborsClassifier(n_neighbors=5, metric='euclidean', algorithm='brute')\n",
        "knn_model_ten_neighbors = KNeighborsClassifier(n_neighbors=10, metric='euclidean', algorithm='brute')\n",
        "\n",
        "kf_knn_model_five_neighbors = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "kf_knn_model_ten_neighbors = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "scores_knn_model_five_neighbors = cross_val_score(knn_model_five_neighbors, X, y, cv=kf_knn_model_five_neighbors, scoring='accuracy')\n",
        "scores_knn_model_ten_neighbors = cross_val_score(knn_model_ten_neighbors, X, y, cv=kf_knn_model_ten_neighbors, scoring='accuracy')\n",
        "\n",
        "mean_accuracy_knn_model_five_neighbors = np.mean(scores_knn_model_five_neighbors) * 100\n",
        "mean_accuracy_knn_model_ten_neighbors = np.mean(scores_knn_model_ten_neighbors) * 100\n",
        "\n",
        "print(\"\\nMédia de acurácia (10 folds) com kNN (k = 5 vizinhos): {:.2f}%\".format(mean_accuracy_knn_model_five_neighbors))\n",
        "print(\"\\nMédia de acurácia (10 folds) com kNN (k = 10 vizinhos): {:.2f}%\".format(mean_accuracy_knn_model_ten_neighbors))\n",
        "\n",
        "print(\"\\n3. MLP com duas arquiteturas diferentes (e com funções de ativação 'Tanh' e 'ReLU' em cada arquitetura):\")\n",
        "\n",
        "mlp_model_one_tanh = MLPClassifier(hidden_layer_sizes=(64,32,16), activation='tanh', max_iter=1200, early_stopping=True, alpha=0.001, learning_rate_init=0.03)\n",
        "mlp_model_one_relu = MLPClassifier(hidden_layer_sizes=(64,32,16), activation='relu', max_iter=1500, early_stopping=True, alpha=0.001, learning_rate_init=0.028)\n",
        "\n",
        "mlp_model_two_tanh = MLPClassifier(hidden_layer_sizes=(128,64,32), activation='tanh', max_iter=1500, early_stopping=True, alpha=0.001, learning_rate_init=0.015)\n",
        "mlp_model_two_relu = MLPClassifier(hidden_layer_sizes=(128,64,32), activation='relu', max_iter=1500, early_stopping=True, alpha=0.001, learning_rate_init=0.015)\n",
        "\n",
        "kf_mlp_model_one_tanh = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "kf_mlp_model_one_relu = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "kf_mlp_model_two_tanh = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "kf_mlp_model_two_relu = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "start_time = time.time()\n",
        "scores_mlp_model_one_tanh = cross_val_score(mlp_model_one_tanh, X, y, cv=kf_mlp_model_one_tanh, scoring='accuracy')\n",
        "elapsed_time_one_tanh = time.time() - start_time\n",
        "mean_accuracy_mlp_model_one_tanh = np.mean(scores_mlp_model_one_tanh) * 100\n",
        "print(\"\\nMédia de acurácia (10 folds) com MLP 1 (tanh): {:.2f}% (Tempo: {:.2f}s)\".format(mean_accuracy_mlp_model_one_tanh, elapsed_time_one_tanh))\n",
        "\n",
        "start_time = time.time()\n",
        "scores_mlp_model_one_relu = cross_val_score(mlp_model_one_relu, X, y, cv=kf_mlp_model_one_relu, scoring='accuracy')\n",
        "elapsed_time_one_relu = time.time() - start_time\n",
        "mean_accuracy_mlp_model_one_relu = np.mean(scores_mlp_model_one_relu) * 100\n",
        "print(\"\\nMédia de acurácia (10 folds) com MLP 1 (relu): {:.2f}% (Tempo: {:.2f}s)\".format(mean_accuracy_mlp_model_one_relu, elapsed_time_one_relu))\n",
        "\n",
        "start_time = time.time()\n",
        "scores_mlp_model_two_tanh = cross_val_score(mlp_model_two_tanh, X, y, cv=kf_mlp_model_two_tanh, scoring='accuracy')\n",
        "elapsed_time_two_tanh = time.time() - start_time\n",
        "mean_accuracy_mlp_model_two_tanh = np.mean(scores_mlp_model_two_tanh) * 100\n",
        "print(\"\\nMédia de acurácia (10 folds) com MLP 2 (tanh): {:.2f}% (Tempo: {:.2f}s)\".format(mean_accuracy_mlp_model_two_tanh, elapsed_time_two_tanh))\n",
        "\n",
        "start_time = time.time()\n",
        "scores_mlp_model_two_relu = cross_val_score(mlp_model_two_relu, X, y, cv=kf_mlp_model_two_relu, scoring='accuracy')\n",
        "elapsed_time_two_relu = time.time() - start_time\n",
        "mean_accuracy_mlp_model_two_relu = np.mean(scores_mlp_model_two_relu) * 100\n",
        "print(\"\\nMédia de acurácia (10 folds) com MLP 2 (relu): {:.2f}% (Tempo: {:.2f}s)\".format(mean_accuracy_mlp_model_two_relu, elapsed_time_two_relu))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
