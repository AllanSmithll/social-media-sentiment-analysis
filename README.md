# Social Media Usage and Emotional Well-being - Machine Learning

Este projeto utiliza algoritmos de aprendizado de m√°quina para analisar a rela√ß√£o entre o uso de redes sociais e o bem-estar emocional. Diversos classificadores foram testados para encontrar o modelo mais adequado.

## üìÇ Estrutura do Projeto
- **Download do dataset**: Obt√©m os dados do Kaggle.
- **Pr√©-processamento**: Trata valores categ√≥ricos e normaliza os dados.
- **Treinamento e avalia√ß√£o**: Testa v√°rios algoritmos, incluindo Decision Tree, kNN, MLP e K-Means.

## üìä Dataset
**Nome:** Social Media Usage and Emotional Well-being  
**Fonte:** Kaggle ([@emirhanai](https://www.kaggle.com/emirhanai))  
**Arquivo principal:** `train.csv`

## üîß Depend√™ncias

Instale as bibliotecas necess√°rias com:

```bash
pip install numpy pandas scikit-learn matplotlib kagglehub
```

## üöÄ Como Executar

1. **Baixar o dataset:**
   ```python
   import kagglehub
   kagglehub.dataset_download("emirhanai/social-media-usage-and-emotional-well-being")
   ```
2. **Executar o script principal:**
   ```bash
   python main.py
   ```

## üèóÔ∏è Pr√©-processamento dos Dados

- **Remo√ß√£o de colunas irrelevantes** (`User_ID`, `Platform`)
- **Filtragem de valores de `Gender`** (`Male`, `Female`, `Non-binary`)
- **Codifica√ß√£o categ√≥rica** com `LabelEncoder` e `OneHotEncoder`
- **Normaliza√ß√£o** com `MinMaxScaler`

## üß† Modelos Utilizados

### 1Ô∏è‚É£ Decision Tree
- **Crit√©rios:** `gini` e `entropy`
- **Valida√ß√£o cruzada:** 10-fold

### 2Ô∏è‚É£ k-Nearest Neighbors (kNN)
- **k = 5 e k = 10**
- **M√©trica:** Dist√¢ncia Euclidiana

### 3Ô∏è‚É£ Multi-layer Perceptron (MLP)

Foram testadas duas arquiteturas diferentes:

- **MLP 1:** `(64, 32, 16)`
- **MLP 2:** `(128, 64, 32)`

Par√¢metros:
- **Fun√ß√£o de ativa√ß√£o:** `tanh` e `relu`
- **Taxa de aprendizado:** `0.03` (MLP 1) e `0.015` (MLP 2)
- **Early stopping:** Ativado

### 4Ô∏è‚É£ K-Means
- **N√∫mero de clusters:** Definido pelo n√∫mero de classes no problema

## üìà Resultados

| Algoritmo | Acur√°cia M√©dia (%) | Taxa de Erro (%) |
|-----------|-------------------|----------------|
| Decision Tree (Gini) | XX | XX |
| Decision Tree (Entropy) | XX | XX |
| kNN (k=5) | XX | XX |
| kNN (k=10) | XX | XX |
| MLP 1 (tanh) | XX | XX |
| MLP 1 (relu) | XX | XX |
| MLP 2 (tanh) | XX | XX |
| MLP 2 (relu) | XX | XX |
| K-Means | XX | XX |

## üìå Visualiza√ß√£o

Para analisar o erro de treinamento ao longo das √©pocas, foi gerado um gr√°fico com a evolu√ß√£o da perda dos modelos MLP.

```python
import matplotlib.pyplot as plt
plt.plot(mlp_one_tanh.loss_curve_, label="MLP 1 (tanh)")
plt.plot(mlp_one_relu.loss_curve_, label="MLP 1 (relu)")
plt.plot(mlp_two_tanh.loss_curve_, label="MLP 2 (tanh)")
plt.plot(mlp_two_relu.loss_curve_, label="MLP 2 (relu)")
plt.xlabel("√âpocas")
plt.ylabel("Erro de Treinamento")
plt.legend()
plt.grid()
plt.show()
```

## üì¢ Conclus√£o
- **MLP apresentou melhor desempenho geral** em termos de acur√°cia.
- **√Årvores de decis√£o** tiveram boa performance com `entropy`.
- **kNN teve performance inferior**, especialmente para `k=10`.
- **K-Means apresentou menor acur√°cia**, pois n√£o √© um classificador supervisionado.

## üèÜ Melhor modelo: `MLP 2 (ReLU)`

Este projeto demonstra o impacto do uso de redes sociais na emo√ß√£o dos usu√°rios, utilizando aprendizado de m√°quina para identificar padr√µes nos dados.

---
‚úâÔ∏è Para d√∫vidas ou sugest√µes, entre em contato!
